## 冯诺伊曼模型
运算器、控制器、存储器、输入设备、输出设备
![alt text](image.png)
![alt text](image-1.png)

## 硬盘内存
当CPU需要访问内存中的某个数据的时候，如果寄存器有这个数据，cpu从寄存器取数据即可，如果没有，就查L1高速缓存，L1没有，就查L2,L2没有就查L3,都没有就去内存中查(其中L1,L2,L3也就是CPU高速缓存)

![alt text](image-3.png)
---
> 其中L1,L2,L3又叫做CPU Cache(高速缓存)
程序执行的时候，会先将内存中的数据加载到共享的L3 cache中，再加载到每个核心独有的L2 Cache中，然后进入到最快的L1 Cache，最后才会被CPU读取

---
![alt text](image-2.png)
## 摩尔定律
CPU的访问速度每18个月就会翻倍

## 什么是字
- “字”不是固定长度，而是由 CPU 决定的。
- 一个“字”是CPU 一次能处理的数据长度。

| CPU 位数   | 一个字的长度       |
| -------- | ------------ |
| 8 位 CPU  | 1 字节（8 bit）  |
| 16 位 CPU | 2 字节（16 bit） |
| 32 位 CPU | 4 字节（32 bit） |
| 64 位 CPU | 8 字节（64 bit） |

## SRAM和DRAM
- SRAM（Static Random Access Memory），中文叫做静态随机存取存储器，是一种 高速、易失性（断电即失） 的半导体存储器，数据在供电期间始终保持，不需要像 DRAM 那样不断刷新，通常6个晶体管

- DRAM,动态随机存取存储器，需要动态刷新，1电容 + 1晶体管

## CPU Cache的数据结构和读取过程
CPU cache是由很多cache line组成的，cache line是cpu从内存中读取数据的基本单位，在 CPU Cache 中的，这样一小块一小块的数据，称为 Cache Line（缓存块）。
![alt text](image-4.png)
CPU 怎么知道要访问的内存数据，是否在 Cache 里？
<br>
直接映射：举个例子，内存共被划分为 32 个内存块，CPU Cache 共有 8 个 CPU Cache Line，假设 CPU 想要访问第 15 号内存块，如果 15 号内存块中的数据已经缓存在 CPU Cache Line 中的话，则是一定映射在 7 号 CPU Cache Line 中，因为 15%8=7
![alt text](image-5.png)

上面例子很容易发现多个内存块的地址会映射到同一个cpu cache line，所以为了区别不同的内存块，在对应的 CPU Cache Line 中我们还会存储一个组标记（Tag）

![alt text](image-6.png)

如果内存中的数据已经在 CPU Cache 中了，那 CPU 访问一个内存地址的时候，会经历这 4 个步骤：
1. 根据内存地址中索引信息，计算在 CPU Cache 中的索引，也就是找出对应的 CPU Cache Line 的地址；
2. 找到对应 CPU Cache Line 后，判断 CPU Cache Line 中的有效位，确认 CPU Cache Line 中数据是否是有效的，如果是无效的，CPU 就会直接访问内存，并重新加载数据，如果数据有效，则往下执行；
3. 对比内存地址中组标记和 CPU Cache Line 中的组标记，确认 CPU Cache Line 中的数据是我们要访问的内存数据，如果不是的话，CPU 就会直接访问内存，并重新加载数据，如果是的话，则往下执行；
4. 根据内存地址中偏移量信息，从 CPU Cache Line 的数据块中，读取对应的字。

## 如何写出CPU跑得更快的代码？
缓存命中率越高的话，代码的性能就会越好，CPU 也就跑的越快。例如1+1=2这个运算，+是指令缓存，而1是数据缓存，所以我们要分开来看「数据缓存」和「指令缓存」的缓存命中率

### 如何提升数据缓存的命中率
下图中形式一的效率远高于形式二，这是因为形式一是按照内存顺序访问的，当arr[0][0]不存在于cpu cache中时，由于cpu会一次性从内存加载一个cache line的大小的数据到cpu cache中，arr[0][0],arr[0][1]...,如果是方式二，cpu就会多次从内存中加载数据到cpu cache中，因为它的访问是跳跃性的、不连续的，多次加载内存中的数据而导致效率下降，而方式一加载一次内存中的数据之后，后续访问的元素都是从cpu cache中加载
![alt text](image-7.png)
遇到这种遍历数组的情况时，按照内存布局顺序访问，将可以有效的利用 CPU Cache 带来的好处，这样我们代码的性能就会得到很大的提升

### 如何提升指令缓存的命中率
如果分支预测可以预测到接下来要执行 if 里的指令，还是 else 指令的话，就可以「提前」把这些指令放在指令缓存中，这样 CPU 可以直接从 Cache 读取到指令，于是执行速度就会很快
![alt text](image-8.png)

先上结论：先排序后遍历赋值的效率更高
<br>
这是因为排完序之后前几次命中if&lt;50的概率比较高，所以会将if中的逻辑array[i]=0缓存到cache中
